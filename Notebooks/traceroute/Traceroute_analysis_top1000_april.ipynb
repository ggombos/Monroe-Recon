{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network level experiments using the Monroe platform\n",
    "\n",
    "There are a quite a few tools experimenter can use to investigate the behaviour of the IP network from an end user's point of view. \n",
    "The proper choice of tool may help to reveal some information about the delays IP fragments experience travelling accross the network or can characterize the temporal capacity conditions or can reveal the topological structure of the network.\n",
    "\n",
    "Trying to take advantage of the fact that Monroe nodes are connected to the network via various access technologies and network providers (we call them operators) we designed experiments, whose goals were to investigate if there are observable differences by the choice of operator.\n",
    "\n",
    "## The description of the experiment\n",
    "\n",
    "In the measurement campaigns in layer 3 the ```traceroute``` application was used.\n",
    "The ```traceroute``` program injects a sequence of IP packets in the computer network with different TTL values so as to capture hop-by-hop IP connectivity.\n",
    "Besides capturing the addresses of the hops dropping the packet due to time to live expired the program also measures the round trip delay for each depth the probe sequence dictates.\n",
    "Note, however, the round trip delay is a composition of several factors, including the queuing delay, the propagation delay and the processing delay.\n",
    "\n",
    "Since the goal is to see if some differentiation can be made according to the operator the edge between the network of the operator and the Internet needs to be identified. \n",
    "Furthermore, within the operator network also a boundary can be defined, which we believe is highly coupled with the structure of the access configuration.\n",
    "The former we call the *gateway* the latter we call the *NAT gateway*.\n",
    "\n",
    "In order to say something statistically signifficant a larger sample was our goal to collect.\n",
    "We achieved it by covering as many Monroe source nodes as available when doing the measurement and also by targetting more nodes.\n",
    "\n",
    "According to the target nodes two measurement scenarios were defined:\n",
    "* PlanetLab targets and\n",
    "* popular sites targets.\n",
    "\n",
    "The PlanetLab is a network of computational resources shared accross the Internet operated mostly by universities and with an academic userbase.\n",
    "\n",
    "In the popular sites case the top 1000 most frequently visited domains are used as targets. **CITATION IS MISSING**\n",
    "\n",
    "In this study we collect our findings for the *popular sites* case.\n",
    "\n",
    "## Objects of investigation\n",
    "\n",
    "### The properties of the *NAT gateways*\n",
    "\n",
    "Based on the IP address sequence the ```traceroute``` collects towards a given target the *NAT gateway* is defined as the first IP address in the public dimain that fulfill the following requirements all.\n",
    "The IP address of the preceeding hop has to be a private address.\n",
    "Those measurements, where the preceeding hop denies telling their IP addresses are dropped, because we cannot be sure wheter that hop is still in the access LAN or the *NAT gateway* itself.\n",
    "\n",
    "Offline after the measurement logs are collected we resolve the autonomous systems (AS) the IP address belong to and keep only those measurements where the resolved AS is in line with the operator of choice.\n",
    "\n",
    "After careful filtering of data we look at\n",
    "* the diameter of the access network, more precisely the hop distance from the measurement node to the *NAT gateway*\n",
    "* the routing strategy, whether the *NAT gateway* tends to be closer to measurement node or the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import urllib\n",
    "import json\n",
    "import ipwhois\n",
    "import socket\n",
    "import sqlite3\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp manipulation\n",
    "\n",
    "The timestamp encoded in the filenames follow a specific pattern.\n",
    "*Note:* my laptop's clock is offset by an hour compared to the timestamps produced by Monroe nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_ts = r'(\\d{4})\\.(\\d{2})\\.(\\d{2})-(\\d{2})\\.(\\d{2})\\.(\\d{2})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thetimestamp(ts, offset = 3600):\n",
    "    _, year, month, day, hour, minute, second, _ = re.split(pattern_ts, ts)\n",
    "    return time.mktime(datetime.datetime(int(year), int(month), int(day), int(hour), int(minute), int(second)).timetuple()) + offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IP address manipulation\n",
    "Most often the IP address (IPv4) is in dotted decimal format, however, for data manipulation we better user 4-byte integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_ipv4 = r'(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip2int(ipaddress):\n",
    "    _, a, b, c, d, _ = re.split(pattern_ipv4, ipaddress)\n",
    "    return (int(a) << 24) + (int(b) << 16) + (int(c) << 8) + int(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2ip(intaddress):\n",
    "    a = (intaddress & 0xff000000) >> 24\n",
    "    b = (intaddress & 0xff0000) >> 16\n",
    "    c = (intaddress & 0xff00) >> 8\n",
    "    d = intaddress & 0xff\n",
    "    return \"%d.%d.%d.%d\" % (a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isprivate(ipaddress):\n",
    "    if isinstance(ipaddress, int):\n",
    "        ipaddress = int2ip(ipaddress)\n",
    "    if ipaddress.startswith('10.'):\n",
    "        return True\n",
    "    if ipaddress.startswith('192.168.'):\n",
    "        return True\n",
    "    if re.match(r'^172\\.1[6-9]\\.', ipaddress) or re.match(r'^172\\.2\\d\\.', ipaddress) or re.match(r'^172\\.3[01]\\.', ipaddress):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a public API to resolve the location of public IP addresses. For most addresses also AS information is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchlocation(ipaddress, extract_keys = ['latitude', 'longitude', 'region_code', 'asn']):\n",
    "    APIurlpattern = 'https://ipapi.co/%s/json/'\n",
    "    if isprivate(ipaddress):\n",
    "        return None, { 'intaddress': ip2int(ipaddress), 'lookupdate': time.time() }\n",
    "    while True:\n",
    "        try:\n",
    "            with urllib.request.urlopen(APIurlpattern % ipaddress) as cm:\n",
    "                resp = cm.read().decode()\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except urllib.error.HTTPError as e:\n",
    "            print (\"Error %s, sleeping\" % e)\n",
    "            time.sleep(10)\n",
    "    respdict = json.loads(resp)\n",
    "    extraction = dict([ (k, respdict.get(k, None)) for k in extract_keys])\n",
    "    extraction['intaddress'] = ip2int(respdict['ip'])\n",
    "    extraction['lookupdate'] = time.time()\n",
    "    return resp, extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use another API to retrieve AS information about a given IP address.\n",
    "The response often contain a whole IP range or even more ranges allocated to a given AS.\n",
    "In order to minimize the number of the remote procedure calls we extract these information, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchasn(ipaddress):\n",
    "    if isprivate(ipaddress):\n",
    "        return None\n",
    "    intaddress = ip2int(ipaddress)\n",
    "    respdict = ipwhois.IPWhois(ipaddress).lookup_whois()\n",
    "    respdict['lookupdate'] = time.time()\n",
    "    respdict['intaddress'] = intaddress\n",
    "    return respdict\n",
    "\n",
    "def cidr2range(cidr):\n",
    "    _, ipaddress, mask, _ = re.split(r'(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})/(\\d+)', cidr)\n",
    "    intaddress = ip2int(ipaddress)\n",
    "    r = 1 << (32 - int(mask))\n",
    "    return { 'ip_min': intaddress, 'ip_max': intaddress + r }\n",
    "\n",
    "def extract_asn(asn_dict):\n",
    "    main_keys = [ 'asn', 'asn_description', 'asn_cidr' ]\n",
    "    t = asn_dict.get('lookupdate', time.time())\n",
    "    a = asn_dict.get('intaddress', None)\n",
    "    def _check(extraction):\n",
    "        has_info = False\n",
    "        for k in main_keys:\n",
    "            if not extraction[k] in [ None, 'NA' ]:\n",
    "                has_info |= True\n",
    "        if has_info:\n",
    "            c = cidr2range(extraction['asn_cidr'])\n",
    "            for k in [ 'ip_min', 'ip_max' ]:\n",
    "                extraction[k] = c[k]\n",
    "            extraction['lookupdate'] = t\n",
    "            extraction['intaddress'] = a\n",
    "            return extraction\n",
    "    extraction = _check( dict([ (k, asn_dict.get(k, None)) for k in main_keys ]) )\n",
    "    if extraction:\n",
    "        yield extraction\n",
    "    if 'nets' in asn_dict:\n",
    "        for x in asn_dict['nets']:\n",
    "            extraction = {\n",
    "                'asn': x.get('name', None),\n",
    "                'asn_description': x.get('description', None)\n",
    "            }\n",
    "            for cidr in re.split(r',\\s*', x.get('cidr', 'NA')):\n",
    "                extraction['asn_cidr'] = cidr\n",
    "                extraction = _check(extraction)\n",
    "                if extraction:\n",
    "                    yield extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Cache\n",
    "\n",
    "Time consuming are calling the AS resolution and location resolution remote functions, and also they impose some quota policies against request frequency, so we try avoiding double look up by saving the responses in a local light weight *sqlite* database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cache:\n",
    "    filename = 'api_cache.db'\n",
    "    schema = {\n",
    "        'ipapi_raw': 'CREATE TABLE ipapi_raw (lookupdate float, response text)',\n",
    "        'ipapi_address': 'CREATE TABLE ipapi_address (lookupdate float, intaddress int, asn text, regioncode text, latitude float, longitude float)',\n",
    "        'ipapi_missing': 'CREATE TABLE ipapi_missing (lookupdate float, intaddress int)',\n",
    "        'asnapi_raw': 'CREATE TABLE asnapi_raw (lookupdate float, response text)',\n",
    "        'asnapi_asn': 'CREATE TABLE asnapi_asn (lookupdate float, intaddress int, asn text, description text, intaddress_min int, intaddress_max int, cidr text)',\n",
    "        'asnapi_missing': 'CREATE TABLE asnapi_missing (lookupdate float, intaddress int)',\n",
    "    }\n",
    "    insert = {\n",
    "        'ipapi_raw': \"INSERT INTO ipapi_raw VALUES (%f,'%s')\",\n",
    "        'ipapi_address': \"INSERT INTO ipapi_address VALUES (%(lookupdate)f, %(intaddress)d, '%(asn)s', '%(region_code)s', %(latitude)f, %(longitude)f)\",\n",
    "        'ipapi_missing': \"INSERT INTO ipapi_missing VALUES (%(lookupdate)f, %(intaddress)d)\",\n",
    "        'asnapi_raw': \"INSERT INTO asnapi_raw VALUES (%f,'%s')\",\n",
    "        'asnapi_asn': \"INSERT INTO asnapi_asn VALUES (%(lookupdate)f, %(intaddress)d, '%(asn)s', '%(asn_description)s', %(ip_min)d, %(ip_max)d, '%(asn_cidr)s')\",\n",
    "        'asnapi_missing': \"INSERT INTO asnapi_missing VALUES (%(lookupdate)f, %(intaddress)d)\",\n",
    "    }\n",
    "    select = {\n",
    "        'ipapi_address': \"SELECT MAX(lookupdate), intaddress, latitude, longitude FROM ipapi_address GROUP BY intaddress\",\n",
    "        'ipapi_missing': \"SELECT intaddress FROM ipapi_missing\",\n",
    "        'asnapi_asn': \"SELECT lookupdate, intaddress_min, intaddress_max, asn, description FROM asnapi_asn\",\n",
    "        'asnapi_missing': \"SELECT intaddress FROM asnapi_missing\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, refresh = False):\n",
    "        self._refresh = refresh\n",
    "        self._ipapi_cache = {}\n",
    "        self._ipapi_missing = set()\n",
    "        self._asnapi_cache = {}\n",
    "        self._asnapi_missing = set()\n",
    "        self.connection = sqlite3.connect(self.filename)\n",
    "        for table, sql in self.schema.items():\n",
    "            try:\n",
    "                self.connection.execute(sql)\n",
    "                self.connection.commit()\n",
    "            except sqlite3.OperationalError:\n",
    "                # table already present\n",
    "                pass\n",
    "        for ts, intaddress, lat, lon in self._select(self.select['ipapi_address']):\n",
    "            self._ipapi_cache[intaddress] = (ts, lat, lon)\n",
    "        for intaddress in self._select(self.select['ipapi_missing']):\n",
    "            self._ipapi_missing.add(intaddress)\n",
    "        for ts, intaddress_min, intaddress_max, asn, asn_description in self._select(self.select['asnapi_asn']):\n",
    "            self._ipapi_cache[intaddress_min, intaddress_max] = (ts, asn, asn_description)\n",
    "        for intaddress in self._select(self.select['asnapi_missing']):\n",
    "            self._asnapi_missing.add(intaddress)\n",
    "        \n",
    "    def _select(self, sql):\n",
    "        crsr = self.connection.cursor()\n",
    "        crsr.execute(sql)\n",
    "        return crsr.fetchall()\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.connection.close()\n",
    "\n",
    "    def ipapi_fetch(self, address):\n",
    "        if isinstance(address, str):\n",
    "            intaddress = ip2int(address)\n",
    "        else:\n",
    "            intaddress = address\n",
    "            address = int2ip(intaddress)\n",
    "        if intaddress in self._ipapi_missing and not self._refresh:\n",
    "            return None\n",
    "        if intaddress in self._ipapi_cache:\n",
    "            return self._ipapi_cache[intaddress]\n",
    "        resp, extraction = fetchlocation(address)\n",
    "        crsr = self.connection.cursor()\n",
    "        if resp is None:\n",
    "            crsr.execute(self.insert['ipapi_missing'] % extraction)\n",
    "            self._ipapi_missing.add(intaddress)\n",
    "            self.connection.commit()\n",
    "            return None\n",
    "        try:\n",
    "            crsr.execute(self.insert['ipapi_raw'] % (extraction['lookupdate'], resp.replace(\"'\", \"\")))\n",
    "        except Exception as e:\n",
    "            print (\"Strange character cannot save raw info\", resp, e)\n",
    "        try:\n",
    "            crsr.execute(self.insert['ipapi_address'] % extraction)\n",
    "        except:\n",
    "            print (\"in\", address)\n",
    "            print (\"extraction\", extraction)\n",
    "#            raise\n",
    "        self._ipapi_cache[intaddress] = (extraction['lookupdate'], extraction['latitude'], extraction['longitude'])\n",
    "        self.connection.commit()\n",
    "        return self._ipapi_cache[intaddress]\n",
    "\n",
    "    def asnapi_fetch(self, address):\n",
    "        if isinstance(address, str):\n",
    "            intaddress = ip2int(address)\n",
    "        else:\n",
    "            intaddress = address\n",
    "            address = int2ip(intaddress)\n",
    "        if intaddress in self._asnapi_missing: #NOTE: no refresh possible, we don't do aggregate query\n",
    "            return None\n",
    "        for (intaddress_min, intaddress_max), info in self._asnapi_cache.items():\n",
    "            if intaddress_min <= intaddress and intaddress <= intaddress_max:\n",
    "                return info\n",
    "        respdict = fetchasn(address)\n",
    "        crsr = self.connection.cursor()\n",
    "        if respdict is None:\n",
    "            crsr.execute(self.insert['asnapi_missing'] % { 'lookupdate': time.time(), 'intaddress': intaddress })\n",
    "            self._asnapi_missing.add(intaddress)\n",
    "            self.connection.commit()\n",
    "            return None\n",
    "        try:\n",
    "            crsr.execute(self.insert['asnapi_raw'] % (respdict['lookupdate'], str(respdict).replace(\"'\", '\"')))\n",
    "        except Exception as e:\n",
    "            print (\"Strange character cannot save raw info\", respdict, e)\n",
    "        info = None\n",
    "        for extraction in extract_asn(respdict):\n",
    "#            crsr = self.connection.cursor()\n",
    "            crsr.execute(self.insert['asnapi_asn'] % extraction)\n",
    "            intaddress_min = extraction['ip_min']\n",
    "            intaddress_max = extraction['ip_max']\n",
    "            item = (extraction['lookupdate'], extraction['asn'], extraction['asn_description'])\n",
    "            self._asnapi_cache[intaddress_min, intaddress_max] = item\n",
    "            if intaddress_min <= intaddress and intaddress <= intaddress_max:\n",
    "                info = item\n",
    "            self.connection.commit()\n",
    "        return info\n",
    "\n",
    "    def asn(self, address):\n",
    "        ts, name, description = self.asnapi_fetch(address)\n",
    "        return \"%s[%s]\" % (name, description)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filename manipulation\n",
    "\n",
    "The ```traceroute``` log filenames encode the following information:\n",
    "* the unique identifier of the Monroe node (**nodeID**),\n",
    "* the network provider (**operator**),\n",
    "* when the measurement took place (**ts**),\n",
    "* the target domain name, whose IP address is resolved (**target**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_traceroute_log = r'^(\\d+)_([^_]+)_([^_]+)_([^_]{19})\\.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_traceroute_filename(fn):\n",
    "    _, nodeID, operator, target, ts, _ = re.split(pattern_traceroute_log, os.path.basename(fn))\n",
    "    if re.match(pattern_ipv4, target):\n",
    "        return { 'ts': thetimestamp(ts), 'nodeID': int(nodeID), 'operator': operator, 'target': ip2int(target) }\n",
    "    address = socket.getaddrinfo(target, 0, 0, 0, 0)[0][4][0]\n",
    "    return { 'ts': thetimestamp(ts), 'nodeID': int(nodeID), 'operator': operator, 'target': ip2int(address), 'target_domain': target }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traceroute representation\n",
    "\n",
    "We implement our own simple represenation of the IP address sequence each measurement yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class traceroute:\n",
    "    pattern_hdr = r'^traceroute to ([\\w\\.-]+)\\s+\\((\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\\), \\d+ hops max, \\d+ byte packets'\n",
    "    pattern_data = r'^\\s?(\\d+)\\s+(.*)'\n",
    "    \n",
    "    def __init__(self, fn):\n",
    "        self._data = {}\n",
    "        self._key = parse_traceroute_filename(fn)\n",
    "        with open(fn) as f:\n",
    "            l = f.readline()\n",
    "            _, target_domain, target, _ = re.split(self.pattern_hdr, l)\n",
    "            self._key['target_in_file'] = ip2int(target)\n",
    "            assert target_domain == self._key['target_domain'], \"Target domain mismatch @ %s\" % fn\n",
    "            for l in f.readlines():\n",
    "                hop, ldata = self.parse_traceroute_line(l)\n",
    "                if hop is not None:\n",
    "                    self._data[int(hop)] = ldata\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_traceroute_line(l):\n",
    "        extract = {}\n",
    "        curr_ip = None\n",
    "        hop = None\n",
    "        try:\n",
    "            _, hop, data, _ = re.split(traceroute.pattern_data, l)\n",
    "            ds = re.split('\\s+(\\d+\\.?\\d*\\s+m?s)\\s*', data)\n",
    "            while len(ds):\n",
    "                h = ds.pop(0)\n",
    "                if len(h) == 0:\n",
    "                    continue\n",
    "                if h == '*':\n",
    "                    continue\n",
    "                elif h[0] == '*':\n",
    "                    ds.insert(0, h.split()[-1])\n",
    "                elif re.match(pattern_ipv4, h):\n",
    "                    curr_ip = ip2int(h)\n",
    "                    if not curr_ip in extract:\n",
    "                        extract[curr_ip] = []\n",
    "                    continue\n",
    "                else:\n",
    "                    _, t, u, _ = re.split('(\\d+\\.?\\d*)\\s(m?s)\\s*', h)\n",
    "                    t = float(t)\n",
    "                    if u == 'ms':\n",
    "                        extract[curr_ip].append(t)\n",
    "                    elif u == 's':\n",
    "                        extract[curr_ip].append(1000 * t)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        return hop, extract\n",
    "    \n",
    "    @property\n",
    "    def complete(self):\n",
    "        return self._key['target'] in self._data[self.maxhop].keys() if self.maxhop > 0 else False\n",
    "    \n",
    "    @property\n",
    "    def maxhop(self): return max(self._data.keys()) if len(self._data.keys()) else -1\n",
    "    \n",
    "    @property\n",
    "    def hoplist(self):\n",
    "        hoplist = []\n",
    "        missing = 0\n",
    "        lastaddress = 0 # the source\n",
    "        for hopid in range(1, self.maxhop + 1):\n",
    "            if len(self._data[hopid]) == 0:\n",
    "                missing += 1\n",
    "                continue\n",
    "            for address in self._data[hopid].keys():\n",
    "                if missing:\n",
    "                    hoplist.append((lastaddress, missing, address))\n",
    "                hoplist.append(address)\n",
    "                missing = 0\n",
    "                lastaddress = address\n",
    "                break\n",
    "        return hoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function pick the *NAT gateway* from a traceroute instance that conform to the definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nat_gw(t):\n",
    "    hops = 0\n",
    "    old_hop = None\n",
    "    for h in t.hoplist:\n",
    "        if isinstance(h, int):\n",
    "            if isprivate(h):\n",
    "                hops += 1\n",
    "                old_hop = h\n",
    "            else:\n",
    "                return { 'gw_nat': h, 'hop': hops, 'asn': C.asn(h), 'previous_hop': old_hop }\n",
    "        else:\n",
    "            hops += h[1]\n",
    "            old_hop = None\n",
    "    return { 'hop': hops }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance formula on the sphere\n",
    "\n",
    "We are still dealing with only a few nodes so there is no problem with using a computationally loaded distance formula.\n",
    "The [Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula) gives the distance between two points on the surface of a sphere along a great circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2, R = 6371):\n",
    "    r = pi / 180.\n",
    "    d_phi = abs(lat1 - lat2)\n",
    "    d_lambda = abs(lon1 - lon2)\n",
    "    sp = sin(r * d_phi / 2)\n",
    "    sl = sin(r * d_lambda / 2)\n",
    "    a =  sp * sp + cos(r * lat1) * cos(r * lat2) * sl * sl\n",
    "    c = 2 * arctan2( sqrt(a), sqrt(1 - a) )\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the date to analyze\n",
    "\n",
    "We access the raw data from our remote server over ssh filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/monroe_node/trace_results/trace_top_1000_apr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load meta information\n",
    "\n",
    "Loading and parsing all the files and looking up the AS information of *NAT gateway* candidates is a time consuming step.\n",
    "When hitting the API request quota, we may stop this loop and restart it after a while.\n",
    "\n",
    "In a filtered table we keep only those traceroute instances that satisfy the following:\n",
    "* at least 2 hops long,\n",
    "* there is a *NAT gateway* candidate,\n",
    "* the *NAT gateway* candidate has a resolvable AS information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ad7365f45e4db2ae769aa52aea062f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e12e3bde16493d8ba4ea1b206dd54e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4910195d21e401fa0bfd7cdca7fe60d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e478cefa294ffd8b9d02f9538d3e6d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prg = ipywidgets.IntText(description = 'Processed', disabled = True)\n",
    "meta = ipywidgets.IntText(description = 'Meta', disabled = True)\n",
    "keep = ipywidgets.IntText(description = 'Kept', disabled = True)\n",
    "oops = ipywidgets.IntText(description = 'Ooopses', disabled = True)\n",
    "display(prg, meta, keep, oops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_meta = []\n",
    "tmp_keep = []\n",
    "resolution_error = []\n",
    "visited = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for fn_w_path in glob.glob(os.path.join(folder, '*txt')):\n",
    "    if fn_w_path in visited:\n",
    "        continue\n",
    "    visited.append(fn_w_path)\n",
    "    try:\n",
    "        k = parse_traceroute_filename(fn_w_path)\n",
    "        prg.value += 1\n",
    "    except ValueError:\n",
    "        # gps data file or anything else with 'txt' filename extension\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        resolution_error.append((fn_w_path, e))\n",
    "        oops.value += 1\n",
    "        continue\n",
    "    try:\n",
    "        t = traceroute(fn_w_path)\n",
    "        k['segments'] = len(t.hoplist)\n",
    "        k['depth'] = t.maxhop\n",
    "        k['complete'] = t.complete\n",
    "    except ValueError:\n",
    "        # zero length file\n",
    "        k['segments'] = -1\n",
    "        k['depth'] = -1\n",
    "        k['complete'] = False\n",
    "    except Exception as e:\n",
    "        resolution_error.append((fn_w_path, e))\n",
    "        oops.value += 1\n",
    "        continue\n",
    "    tmp_meta.append(k)\n",
    "    meta.value += 1\n",
    "    if k['segments'] > 2:\n",
    "        nat_gw = find_nat_gw(t)\n",
    "        if not 'asn' in nat_gw:\n",
    "            continue\n",
    "        if nat_gw['previous_hop'] is None:\n",
    "            continue # the former hop is a * in the traceroute\n",
    "        k['gw_nat_asn'] = nat_gw['asn']\n",
    "        k['gw_nat'] = nat_gw['gw_nat']\n",
    "        k['gw_nat_hop'] = nat_gw['hop']\n",
    "        tmp_keep.append(k)\n",
    "        keep.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_meta = pandas.DataFrame(tmp_meta)\n",
    "pd_filter1 = pandas.DataFrame(tmp_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complete</th>\n",
       "      <th>depth</th>\n",
       "      <th>gw_nat</th>\n",
       "      <th>gw_nat_asn</th>\n",
       "      <th>gw_nat_hop</th>\n",
       "      <th>nodeID</th>\n",
       "      <th>operator</th>\n",
       "      <th>segments</th>\n",
       "      <th>target</th>\n",
       "      <th>target_domain</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>1.047727e+09</td>\n",
       "      <td>None[TELIANET-BLK]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>588</td>\n",
       "      <td>YOIGO</td>\n",
       "      <td>16</td>\n",
       "      <td>2067381429</td>\n",
       "      <td>bjlidu.net</td>\n",
       "      <td>1.523369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>1.407199e+09</td>\n",
       "      <td>None[VODAFONE-IT 1st Alloc route]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>610</td>\n",
       "      <td>vodafone-IT</td>\n",
       "      <td>13</td>\n",
       "      <td>3267060415</td>\n",
       "      <td>pipeschannels.com</td>\n",
       "      <td>1.523375e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612</td>\n",
       "      <td>I-WIND</td>\n",
       "      <td>2</td>\n",
       "      <td>1607717064</td>\n",
       "      <td>cam4.com</td>\n",
       "      <td>1.523373e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612</td>\n",
       "      <td>I-WIND</td>\n",
       "      <td>0</td>\n",
       "      <td>2328434473</td>\n",
       "      <td>msvportal.de</td>\n",
       "      <td>1.523369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>587</td>\n",
       "      <td>Orange</td>\n",
       "      <td>6</td>\n",
       "      <td>100663110</td>\n",
       "      <td>yandex.ru</td>\n",
       "      <td>1.523373e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  complete  depth        gw_nat                         gw_nat_asn  \\\n",
       "0     True     22  1.047727e+09                 None[TELIANET-BLK]   \n",
       "1     True     14  1.407199e+09  None[VODAFONE-IT 1st Alloc route]   \n",
       "2    False     64           NaN                                NaN   \n",
       "3    False     64           NaN                                NaN   \n",
       "4    False     64           NaN                                NaN   \n",
       "\n",
       "   gw_nat_hop  nodeID     operator  segments      target      target_domain  \\\n",
       "0         5.0     588        YOIGO        16  2067381429         bjlidu.net   \n",
       "1         6.0     610  vodafone-IT        13  3267060415  pipeschannels.com   \n",
       "2         NaN     612       I-WIND         2  1607717064           cam4.com   \n",
       "3         NaN     612       I-WIND         0  2328434473       msvportal.de   \n",
       "4         NaN     587       Orange         6   100663110          yandex.ru   \n",
       "\n",
       "             ts  \n",
       "0  1.523369e+09  \n",
       "1  1.523375e+09  \n",
       "2  1.523373e+09  \n",
       "3  1.523369e+09  \n",
       "4  1.523373e+09  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complete</th>\n",
       "      <th>depth</th>\n",
       "      <th>gw_nat</th>\n",
       "      <th>gw_nat_asn</th>\n",
       "      <th>gw_nat_hop</th>\n",
       "      <th>nodeID</th>\n",
       "      <th>operator</th>\n",
       "      <th>segments</th>\n",
       "      <th>target</th>\n",
       "      <th>target_domain</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>1047727417</td>\n",
       "      <td>None[TELIANET-BLK]</td>\n",
       "      <td>5</td>\n",
       "      <td>588</td>\n",
       "      <td>YOIGO</td>\n",
       "      <td>16</td>\n",
       "      <td>2067381429</td>\n",
       "      <td>bjlidu.net</td>\n",
       "      <td>1.523369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>1407199326</td>\n",
       "      <td>None[VODAFONE-IT 1st Alloc route]</td>\n",
       "      <td>6</td>\n",
       "      <td>610</td>\n",
       "      <td>vodafone-IT</td>\n",
       "      <td>13</td>\n",
       "      <td>3267060415</td>\n",
       "      <td>pipeschannels.com</td>\n",
       "      <td>1.523375e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>1407199326</td>\n",
       "      <td>VODAFONE-IT[Ip addresses allocated to Vodafone...</td>\n",
       "      <td>6</td>\n",
       "      <td>570</td>\n",
       "      <td>vodafone-IT</td>\n",
       "      <td>14</td>\n",
       "      <td>1211369669</td>\n",
       "      <td>souq.com</td>\n",
       "      <td>1.523375e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>1373919321</td>\n",
       "      <td>None[TELIANET-BLK]</td>\n",
       "      <td>3</td>\n",
       "      <td>428</td>\n",
       "      <td>Telia</td>\n",
       "      <td>10</td>\n",
       "      <td>2538622182</td>\n",
       "      <td>anapeyma.com</td>\n",
       "      <td>1.523369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>1047727417</td>\n",
       "      <td>None[TELIANET-BLK]</td>\n",
       "      <td>5</td>\n",
       "      <td>572</td>\n",
       "      <td>YOIGO</td>\n",
       "      <td>7</td>\n",
       "      <td>1745883101</td>\n",
       "      <td>quizlet.com</td>\n",
       "      <td>1.523369e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  complete  depth      gw_nat  \\\n",
       "0     True     22  1047727417   \n",
       "1     True     14  1407199326   \n",
       "2     True     15  1407199326   \n",
       "3    False     64  1373919321   \n",
       "4    False     64  1047727417   \n",
       "\n",
       "                                          gw_nat_asn  gw_nat_hop  nodeID  \\\n",
       "0                                 None[TELIANET-BLK]           5     588   \n",
       "1                  None[VODAFONE-IT 1st Alloc route]           6     610   \n",
       "2  VODAFONE-IT[Ip addresses allocated to Vodafone...           6     570   \n",
       "3                                 None[TELIANET-BLK]           3     428   \n",
       "4                                 None[TELIANET-BLK]           5     572   \n",
       "\n",
       "      operator  segments      target      target_domain            ts  \n",
       "0        YOIGO        16  2067381429         bjlidu.net  1.523369e+09  \n",
       "1  vodafone-IT        13  3267060415  pipeschannels.com  1.523375e+09  \n",
       "2  vodafone-IT        14  1211369669           souq.com  1.523375e+09  \n",
       "3        Telia        10  2538622182       anapeyma.com  1.523369e+09  \n",
       "4        YOIGO         7  1745883101        quizlet.com  1.523369e+09  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_filter1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure data is stored\n",
    "\n",
    "Because parsing the raw files is very expensive in terms of time, we save the formerly extracted information right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_meta.to_pickle('meta-apr.pandas')\n",
    "pd_filter1.to_pickle('filter1-apr.pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHECKPOINT:** Here is how to read back the extracted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_meta = pandas.read_pickle('meta-apr.pandas')\n",
    "pd_filter1 = pandas.read_pickle('filter1-apr.pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of raw traceroute log files that contain any information and those kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('# measurements:', len(pd_meta), len(pd_filter1))\n",
    "print ('success ratio:', len(pd_filter1) / len(pd_meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of source nodes, destinations and operators involved in the measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('# different targets', len(set(pd_filter1['target'])))\n",
    "print ('# sources', len(set(pd_filter1['nodeID'])))\n",
    "print ('# operator', len(set(pd_filter1['operator'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of complete traceroutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_complete = sum(pd_filter1['complete'] == True)\n",
    "print ('# target reached', n_complete)\n",
    "print (' success ratio', n_complete / len(pd_filter1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the details by operators.\n",
    "<a id='operator_complete'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_filter1.groupby(['operator', 'complete']).agg({ 'ts' :'count'}).rename(columns = {'ts': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "* I-WIND produced no complete traceroute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate *NAT gateway* AS-s\n",
    "\n",
    "By the definition the *NAT gateway* must belong to an AS, which relates to the given operator. \n",
    "In few cases it may happen the *NAT gateway* candidate has an AS resolved that does not conform with this expectation.\n",
    "We need to filter them out and we do it manually as there is no strict rules to the string representation of the various AS-s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = set(pd_filter1['operator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optable = dict( [ (op, pd_filter1[pd_filter1['operator'] == op]) for op in operators ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(op = operators)\n",
    "def count_gw_as(op):\n",
    "    return optable[op].groupby(by = ['gw_nat_asn']).agg({ 'ts': 'count'}).rename(columns = {'ts': 'count'}).sort_values(by = 'count', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* Orange gw reside in 3rd party network providers (Microsoft, Amazon). Too few samples.\n",
    "* No samples from Telenor-SE, I-TIM, TelenorS, Telia-N\n",
    "* 242-14 few gw reside in a different as than expected, keeping \"None[VENTELO-NO-ROUTE]\"\n",
    "* 3 the top four as are kept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter alien AS-es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_op = ['Orange', 'Telenor-SE', 'I-TIM', 'TelenorS', 'Telia-N', 'I-WIND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators_filtered = operators.difference(set(drop_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optable_filtered = {}\n",
    "for op, opt in optable.items():\n",
    "    if op in drop_op:\n",
    "        continue\n",
    "    if op == '242-14':\n",
    "        t = opt[opt['gw_nat_asn'] == \"None[VENTELO-NO-ROUTE]\"]\n",
    "    elif op == '3':\n",
    "        KEEP = [\"None[HI3G]\", \"None[IP-ONLY]\", \"HI3GACCESS[Hi3G Streaming Servers\\nHi3g Access AB\\nLindhagensgatan 98\\nSE-104 25 Stockholm]\", \"NETNOD-IX-STH-GE[Stockholm Interconnect GigEth\\nId:inetnum194.68.123.0−24,v1.12010−05−2108:53:56nicoExpId:inetnum194.68.123.0−24,v1.12010−05−2108:53:56nicoExp]\"]\n",
    "        t = pandas.concat([ opt[opt['gw_nat_asn'] == a] for a in KEEP ])\n",
    "    else:\n",
    "        t = opt\n",
    "    optable_filtered[op] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hopcount\n",
    "\n",
    "We analyse the diameter of the access network i.e. the hop count between the Monroe node and the *NAT gateway*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hopcount(op):\n",
    "    f = optable_filtered[op][optable_filtered[op]['complete'] == True]\n",
    "    return f[['gw_nat_hop', 'depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diam = 1 + max([ max(hopcount(op)['gw_nat_hop']) for op in operators_filtered ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(op = operators_filtered)\n",
    "def pl(op):\n",
    "    try:\n",
    "        hopcount(op).plot.scatter('gw_nat_hop', 'depth', grid = True)\n",
    "        xticks(range(max_diam), range(1, max_diam + 1))\n",
    "    except:\n",
    "        title('No data')\n",
    "        plot([0], [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "According to the operator there are two strategies we can spot. Either a single radius describes the access network diameter or two different radii. Interesting to see the two Telia operators share the same radii, which may be the footprint of they following the same technological and configurational scheme.\n",
    "\n",
    "* 242-14 single gw distance: 5\n",
    "* vodafone-IT single gw distance: 7\n",
    "* YOIGO single gw distance: 6\n",
    "* N-telenor single gw distance: 2 [too few samples]\n",
    "* Telia-S gw distances are: 2, 4\n",
    "* Telia gw distances are: 2, 4\n",
    "* 3 gw distances are: 5, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance\n",
    "\n",
    "Investigate geographical distances related to the *NAT gateways*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the node positions retrieved by the help of `cassandra` API and double check that all nodes are covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_positions = pandas.read_csv('monroegps-20180426.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeids_in_csv = set(node_positions['nodeid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeids_in_filteredtable = set(pd_filter1['nodeID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"# nodes in the experiment\", len(nodeids_in_filteredtable))\n",
    "print (\"Missing ids\", nodeids_in_filteredtable.difference(nodeids_in_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to further filter our dataset to keep only those logs that reached the target.\n",
    "Visit [the former table](#operator_complete) to see how many data are kept versus all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optable_complete = dict([ (op, opt[opt['complete'] == True]) for op, opt in optable_filtered.items() ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up the coordinates of the *NAT gateways* kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prg_ip = ipywidgets.IntText(description = 'Processed', disabled = True)\n",
    "display(prg_ip)\n",
    "i = 0\n",
    "for opt in optable_complete.values():\n",
    "    for _, r in opt[['gw_nat', 'target']].iterrows():\n",
    "        C.ipapi_fetch(r['gw_nat'])\n",
    "        C.ipapi_fetch(r['target'])\n",
    "        prg_ip.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for opt in optable_complete.values():\n",
    "    if len(opt) == 0:\n",
    "        continue\n",
    "    opt['gw_loc'] = opt['gw_nat'].map(C.ipapi_fetch)\n",
    "    opt['target_loc'] = opt['target'].map(C.ipapi_fetch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the distance between the target and the *NAT gateway*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for opt in optable_complete.values():\n",
    "    if len(opt) == 0:\n",
    "        continue\n",
    "    dl = []\n",
    "    for _, r in opt.iterrows():\n",
    "        _, lat1, lon1 = r['gw_loc']\n",
    "        _, lat2, lon2 = r['target_loc']\n",
    "        try:\n",
    "            dl.append( haversine(lat1, lon1, lat2, lon2) )\n",
    "        except:\n",
    "            # any coordinate is null\n",
    "            dl.append(-1)\n",
    "    opt['dst_gw_target'] = dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join tables so Monroe node coordinates are present in the filtered dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME:** we should use `pandas.merge()`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for opt in optable_complete.values():\n",
    "    if len(opt) == 0:\n",
    "        continue\n",
    "    pl = []\n",
    "    dl = []\n",
    "    for _, r in opt.iterrows():\n",
    "        _, lat1, lon1 = r['gw_loc']\n",
    "        nodeid = r['nodeID']\n",
    "        _, lat2, lon2 = node_positions[ node_positions['nodeid'] == nodeid ].values[0]\n",
    "        pl.append((None, lat2, lon2))\n",
    "        try:\n",
    "            dl.append( haversine(lat1, lon1, lat2, lon2) )\n",
    "        except:\n",
    "            # any coordinate is null\n",
    "            dl.append(-1)\n",
    "    opt['source_loc'] = pl\n",
    "    opt['dst_source_gw'] = dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(op = operators_filtered, bins = ipywidgets.IntText(value = 100))\n",
    "def dst_hist(op, bins):\n",
    "    subplot(2, 1, 1)\n",
    "    try:\n",
    "        optable_complete[op]['dst_source_gw'].plot.hist(bins = bins)\n",
    "    except:\n",
    "        title('No data')\n",
    "        plot([0], [0])\n",
    "    subplot(2, 1, 2)\n",
    "    try:\n",
    "        optable_complete[op]['dst_gw_target'].plot.hist(bins = bins)\n",
    "    except:\n",
    "        title('No data')\n",
    "        plot([0], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(op = operators_filtered)\n",
    "def distance_scatter(op):\n",
    "    try:\n",
    "        optable_complete[op].plot.scatter('dst_source_gw', 'dst_gw_target')\n",
    "    except:\n",
    "        title('No data')\n",
    "        plot([0], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(op = operators_filtered)\n",
    "def distance2_scatter(op):\n",
    "    try:\n",
    "        optable_complete[op].plot.scatter('dst_source_gw', 'gw_nat_hop')\n",
    "    except:\n",
    "        title('No data')\n",
    "        plot([0], [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "* A similar pattern is found as in the hopcount case.\n",
    "  Namely, either a unimodal or a bimodal distance distribution describes well the geographical distance between the source node and the *NAT gateway*, whereas the distance between the *NAT gateway* and the target vary in a wide range.\n",
    "* Operator 3: the smaller diameter correspond to smaller distance, the greater diameter map to both short and long distances\n",
    "* Operator Telia: all combinations of hop distances and geographical distances are present (**TODO: count frequency**)\n",
    "* Operator Telia-S: small diameter correspond to short distance, greater diameter to somewhat longer distance, note however, the factor is just around two.\n",
    "* Operator YOIGO and Vodafone-IT: both have single radii, but the geographical distances are showing two relatively long distance manifestations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *gateway* investigation\n",
    "\n",
    "We need to parse those traceroutes once again which we kept filtered and complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_fn(r):\n",
    "    #TODO: clean it up and push up in notebook\n",
    "    ts = datetime.datetime.fromtimestamp(r[3] - 3600).strftime('%Y.%m.%d-%H.%M.%S')\n",
    "    return \"%d_%s_%s_%s.txt\" % (r[0], r[1], r[2], ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceroute_in_memory = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prg_reload = ipywidgets.IntProgress(value = len(traceroute_in_memory), max = sum([ len(opt) for opt in optable_complete.values() ]))\n",
    "display(prg_reload)\n",
    "\n",
    "oppa = 0\n",
    "\n",
    "for opt in optable_complete.values():\n",
    "    if len(opt) == 0:\n",
    "        continue\n",
    "    for r in opt[['nodeID', 'operator', 'target_domain', 'ts']].values:\n",
    "        k = tuple(r)\n",
    "        if k in traceroute_in_memory:\n",
    "            continue\n",
    "        try:\n",
    "            traceroute_in_memory[k] = traceroute(os.path.join(folder, trt_fn(r)))\n",
    "        except:\n",
    "            oppa += 1\n",
    "        prg_reload.value += 1\n",
    "print (\"# errors\", oppa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up AS-es in the rest of the traceroute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_as(t, gwn):\n",
    "    found_gw = False\n",
    "    ass = []\n",
    "    for h in t.hoplist:\n",
    "        if not found_gw:\n",
    "            if gwn != h:\n",
    "                continue\n",
    "            else:\n",
    "                found_gw = True\n",
    "        if isinstance(h, int):\n",
    "            ass.append(C.asn(h))\n",
    "        else:\n",
    "            # asterisk in traceroute\n",
    "            ass.append(None)\n",
    "    return ass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_chain = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_oops = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prg_aslu = ipywidgets.IntProgress(value = len(as_chain), max = sum([ len(opt) for opt in optable_complete.values() ]))\n",
    "display(prg_aslu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for opt in optable_complete.values():\n",
    "    if len(opt) == 0:\n",
    "        continue\n",
    "    for r in opt[['nodeID', 'operator', 'target_domain', 'ts', 'gw_nat']].values:\n",
    "        k = tuple(r[:-1])\n",
    "        if k in as_chain:\n",
    "            continue\n",
    "        try:\n",
    "            as_chain[k] = lookup_as(traceroute_in_memory[k], r[-1])\n",
    "        except:\n",
    "            as_oops.append(r)\n",
    "        prg_aslu.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"# as chains\", len(as_chain))\n",
    "print (\"# excpetions\", len(as_oops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* Filtering is not automated at this pont, we peeking into the data for all operators one-by-one and build the mapping criteria manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operators_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k, v in as_chain.items():\n",
    "#    if k[1] == 'YOIGO':\n",
    "#        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME: let it be a traceroute method\n",
    "def get_hop(trt, n):\n",
    "    for h in trt.hoplist:\n",
    "        if isinstance(h, int):\n",
    "            n -= 1\n",
    "        else:\n",
    "            n -= h[1]\n",
    "        if n == 0:\n",
    "            return h\n",
    "        elif n < 0:\n",
    "#            print (\"OOOPS\")\n",
    "            return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lu_gw(op_label, pattern):\n",
    "    gwdict = {}\n",
    "    for k, v in as_chain.items():\n",
    "        if k[1] == op_label:\n",
    "            thenode, theop, thetarget, thets = k\n",
    "            mask1 = optable_filtered[theop]['ts'] == thets\n",
    "            mask2 = optable_filtered[theop]['target_domain'] == thetarget\n",
    "            mask3 = optable_filtered[theop]['nodeID'] == thenode\n",
    "            thehop = optable_filtered[theop][mask1 & mask2 & mask3]['gw_nat_hop'].values[0] + 1\n",
    "            for ashop in v:\n",
    "                if ashop is None:\n",
    "                    break\n",
    "                elif re.match(pattern, ashop.lower()):\n",
    "                    thehop += 1\n",
    "                else:\n",
    "                    break\n",
    "            thetrt = traceroute_in_memory[k]\n",
    "            gwdict[k] = thehop, get_hop(thetrt, thehop)\n",
    "    return gwdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lu_gw(gwdict):\n",
    "    gwdict_filter = {}\n",
    "    complementer = {}\n",
    "    for k, v in gwdict.items():\n",
    "        hc, h = v\n",
    "        if isinstance(h, int):\n",
    "            gwdict_filter[k] = v\n",
    "        else:\n",
    "            complementer[k] = h[2]\n",
    "    print (\"# gw all\", len(gwdict))\n",
    "    print (\"# gw filtered\", len(gwdict_filter))\n",
    "    print (\"# gw following an askerisk\", len(complementer))\n",
    "    print (\"# different gw addresses\", len(set([ x for x in gwdict_filter.values() ])))\n",
    "    print (\"# different addresses after asterisk\", len(set([ x for x in complementer.values() ])))\n",
    "    return gwdict_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_filter = {}\n",
    "for op_label, pattern in [\n",
    "    ('vodafone-IT', r'.*vodafone'),\n",
    "    ('Telia', r'.*telia'),\n",
    "    ('TELIA-S', r'.*telia'),\n",
    "    ('YOIGO', r'.*telia'),\n",
    "    ('242-14', r'.*ventelo'),\n",
    "    ('3', r'.*hi3g'),\n",
    "]:\n",
    "    print (\"OPERATOR: %s\\n=============\" % op_label)\n",
    "    tmp = lu_gw(op_label, pattern)\n",
    "    gw_filter[op_label] = filter_lu_gw(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = lu_gw('3', r'.*ip-only')\n",
    "tmp = filter_lu_gw(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* operator network YOIGO contains far too many gateways, we will not analyze them\n",
    "* operator network 3 was broken into two sets, however for the time being we stick to the AS hi3g and will not analyze AS ip-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for op_label in operators_filtered:\n",
    "    if not op_label in gw_filter:\n",
    "        print (\"No data for operator\", op_label)\n",
    "        continue\n",
    "    if not op_label in optable_complete:\n",
    "        print (\"No data for operator\", op_label)\n",
    "        continue\n",
    "    gw_dict = gw_filter[op_label]\n",
    "    opt = optable_complete[op_label]\n",
    "    gwl = []\n",
    "    gwhl = []\n",
    "    for _, r in opt.iterrows():\n",
    "        k = r['nodeID'], r['operator'], r['target_domain'], r['ts']\n",
    "        if k in gw_dict:\n",
    "            hc, h = gw_dict[k]\n",
    "            gwl.append(int(h))\n",
    "            gwhl.append(hc)\n",
    "        else:\n",
    "            gwl.append(int(0))\n",
    "            gwhl.append(-1)\n",
    "    opt['gw'] = gwl\n",
    "    opt['hopcount_gw'] = gwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "optable_complete_2 = {}\n",
    "for op_label in operators_filtered:\n",
    "    if not op_label in optable_complete:\n",
    "        continue\n",
    "    if not op_label in gw_filter:\n",
    "        continue\n",
    "    optable_complete_2[op_label] = optable_complete[op_label][optable_complete[op_label]['gw'] > 0]\n",
    "    optable_complete_2[op_label]['gw2_loc'] = optable_complete_2[op_label]['gw'].map(C.ipapi_fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for opt in optable_complete_2.values():\n",
    "    d1l = []\n",
    "    d2l = []\n",
    "    dl = []\n",
    "    for _, r in opt.iterrows():\n",
    "        _, lat0, lon0 = r['source_loc']\n",
    "        _, lat1, lon1 = r['gw2_loc']\n",
    "        _, lat2, lon2 = r['target_loc']\n",
    "        try:\n",
    "            dl.append( haversine(lat0, lon0, lat2, lon2) )\n",
    "        except:\n",
    "            # any coordinate is null\n",
    "            dl.append(-1)\n",
    "        try:\n",
    "            d1l.append( haversine(lat0, lon0, lat1, lon1) )\n",
    "        except:\n",
    "            # any coordinate is null\n",
    "            d1l.append(-1)\n",
    "        try:\n",
    "            d2l.append( haversine(lat1, lon1, lat2, lon2) )\n",
    "        except:\n",
    "            # any coordinate is null\n",
    "            d2l.append(-1)\n",
    "    opt['dst_source_gw2'] = d1l\n",
    "    opt['dst_gw2_target'] = d2l\n",
    "    opt['dst_source_target'] = dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optable_complete_distancevalid = {}\n",
    "for op_label, opt in optable_complete_2.items():\n",
    "    m1 = opt['dst_source_target'] > 0\n",
    "    m2 = opt['dst_source_gw'] > 0\n",
    "    m3 = opt['dst_source_gw2'] > 0\n",
    "    m4 = opt['dst_gw_target'] > 0\n",
    "    m5 = opt['dst_gw2_target'] > 0\n",
    "    m = m1 & m2 & m3 & m4 & m5\n",
    "    print (\"# records for operator %s: %d\" % (op_label, len(m)))\n",
    "    print (\"# records kept for operator %s: %d\" % (op_label, sum(m)))\n",
    "    if sum(m):\n",
    "        optable_complete_distancevalid[op_label] = opt[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op_label, opt in optable_complete_distancevalid.items():\n",
    "    opt.to_pickle('filter2-%s.pandas' % op_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(op = list(optable_complete_distancevalid.keys()))\n",
    "def plot_dst(op):\n",
    "    opt = optable_complete_distancevalid[op]\n",
    "    subplot(2, 1, 1)\n",
    "    title('NAT gateway')\n",
    "    plot(opt['dst_gw_target'], opt['dst_source_gw'], '.')\n",
    "    xlabel('normed gw -> target')\n",
    "    ylabel('normed source -> gw')\n",
    "    subplot(2, 1, 2)\n",
    "    title('gateway')\n",
    "    plot(opt['dst_gw2_target'], opt['dst_source_gw2'], '.')\n",
    "    xlabel('normed gw -> target')\n",
    "    ylabel('normed source -> gw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(op = list(optable_complete_distancevalid.keys()))\n",
    "def plot_normed(op):\n",
    "    opt = optable_complete_distancevalid[op]\n",
    "    subplot(2, 1, 1)\n",
    "    title('NAT gateway')\n",
    "    plot(opt['dst_gw_target'] / opt['dst_source_target'], opt['dst_source_gw'] / opt['dst_source_target'], '.')\n",
    "    xlabel('normed gw -> target')\n",
    "    ylabel('normed source -> gw')\n",
    "    subplot(2, 1, 2)\n",
    "    title('gateway')\n",
    "    plot(opt['dst_gw2_target'] / opt['dst_source_target'], opt['dst_source_gw2'] / opt['dst_source_target'], '.')\n",
    "    xlabel('normed gw -> target')\n",
    "    ylabel('normed source -> gw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact(op = list(optable_complete_distancevalid.keys()), bins = ipywidgets.IntText(value = 100))\n",
    "def dst_hist(op, bins):\n",
    "    opt = optable_complete_distancevalid[op]\n",
    "    subplot(2, 2, 1)\n",
    "    c, e = histogram(opt['dst_source_gw'] / opt['dst_source_target'], bins = bins)\n",
    "    plot(.5*(e[1:]+e[:-1]), c)\n",
    "    subplot(2, 2, 2)\n",
    "    c, e = histogram(opt['dst_source_gw2'] / opt['dst_source_target'], bins = bins)\n",
    "    plot(.5*(e[1:]+e[:-1]), c)\n",
    "    subplot(2, 2, 3)\n",
    "    c, e = histogram(opt['dst_gw_target'] / opt['dst_source_target'], bins = bins)\n",
    "    plot(.5*(e[1:]+e[:-1]), c)\n",
    "    subplot(2, 2, 4)\n",
    "    c, e = histogram(opt['dst_gw2_target'] / opt['dst_source_target'], bins = bins)\n",
    "    plot(.5*(e[1:]+e[:-1]), c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
